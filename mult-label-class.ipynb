{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "\n",
    "pip install scikit-multilearn\n",
    "pip install imbalanced-learn\n",
    "pip install nltk\n",
    "pip install spacy\n",
    "pip install pickle\n",
    "python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tratamento de dados pandas\n",
    "import pandas as pd\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "#Salvar modelos\n",
    "import pickle\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "#Vect\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Especifique o caminho completo para o arquivo CSV\n",
    "caminho_arquivo = \"/eduardo.morais/train.csv\"\n",
    "\n",
    "#Use a função read_csv para carregar o arquivo\n",
    "df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lematizar palavras\n",
    "def lematiza(text):\n",
    "  \n",
    "  doc = nlp(text)\n",
    "  tokens_alpha = [token.lemma_ for token in doc if token.is_alpha]\n",
    "  return \" \".join(tokens_alpha)\n",
    "\n",
    "#lematizar aplicando funcao ja definida\n",
    "df['text'] = df['comment_text'].map(lambda x : lematiza(x))\n",
    "\n",
    "#dividir bases\n",
    "df_treino, df_teste = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria vect, treina e salva modelo\n",
    "def vectTreino(X,nome_modelo):\n",
    "     \n",
    " #define parametros vect\n",
    "  vect = TfidfVectorizer(\n",
    "                       stop_words=sw.words('english'), \n",
    "                       ngram_range=(1, 3), #considera trigrams\n",
    "                       strip_accents='unicode', #desconsidera acentos\n",
    "                       min_df=2, #min para considerar\n",
    "                       max_df=0.8, #max ocorrencias\n",
    "                       lowercase=True, #tudo em minusculo\n",
    "                          )\n",
    "  #treinando\n",
    "  X_dtm = vect.fit_transform(X)\n",
    "  #nome de pasta para salvar modelo\n",
    "  folder = \"/eduardo.morais/\"+nome_modelo+\"/vect/\"\n",
    "  #cria pasta para salvar vect\n",
    "  dbutils.fs.mkdirs(folder)\n",
    "  #salvando vect\n",
    "  filename = folder  + 'vect.sav'\n",
    "  pickle.dump(vect, open(filename, 'wb'))\n",
    "\n",
    "  return X_dtm\n",
    "\n",
    "#cria variavel X\n",
    "X = df_treino.text\n",
    "\n",
    "#executa vect\n",
    "X_dtm = vectTreino(X, \"wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo \n",
    "def TrainModel(X_dtm,df_pandas,nome_modelo,model):\n",
    "\n",
    "  folder = \"/eduardo.morais/\"+nome_modelo+\"/multi-label/\"\n",
    "  dbutils.fs.rm ( folder, True ) #exclui pasta\n",
    "  dbutils.fs.mkdirs(folder) #cria pasta para salvar vect\n",
    "\n",
    "  #for para criar modelos\n",
    "  for label in categorias_list: \n",
    "\n",
    "    print('Processando: {}'.format(label))\n",
    "    y = df_pandas[label]\n",
    "\n",
    "    #Corrige desbalanceamento\n",
    "    oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "    X = X_dtm\n",
    "    X, y = oversampler.fit_resample(X, y)\n",
    "\n",
    "    #Treinar o modelo usando X & y\n",
    "    model.fit(X, y)\n",
    "\n",
    "    #salvar model\n",
    "    filename = folder + label.replace(\"/\", \"|\") + '.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "#modelo GradientBososting\n",
    "model = GradientBoostingClassifier(n_estimators=100,loss='exponential')\n",
    "\n",
    "#listar categorias\n",
    "categorias_list = ['obscene','insult','toxic',\n",
    "'severe_toxic','identity_hate','threat']\n",
    "\n",
    "#modelo execucao\n",
    "TrainModel(X_dtm,df_treino,\"wikipedia\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega e executa vect\n",
    "def vectCarrega(X,nome_modelo):\n",
    "     \n",
    "  #nome de pasta para carregar o modelo\n",
    "  folder = \"/eduardo.morais/\"+nome_modelo+\"/vect/\"\n",
    "  #carregando o vect\n",
    "  filename = folder  + 'vect.sav'\n",
    "  vect = pickle.load(open(filename, 'rb'))\n",
    "  #executar modelo carregado\n",
    "  X_dtm = vect.transform(X)\n",
    "\n",
    "  return X_dtm\n",
    "\n",
    "#cria variavel X\n",
    "X = df_teste.text\n",
    "\n",
    "#executa vect\n",
    "X_dtm = vectCarrega(X, \"wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo carregamento\n",
    "def ModelLoad(X_dtm,df_teste,nome_modelo):\n",
    "\n",
    "  #nome de pasta para carregar modelo\n",
    "  folder = \"/eduardo.morais/\"+nome_modelo+\"/multi-label/\"\n",
    "\n",
    "  for label in categorias_list:\n",
    "    print(label)\n",
    "\n",
    "    filename = folder + label.replace(\"/\", \"|\") + '.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #Fazer previsões a partir do conjunto de teste (X_dtm)\n",
    "    y_pred = model.predict(X_dtm)\n",
    "    y = df_teste[label]\n",
    "\n",
    "    print('Teste Acurácia: {}'.format(accuracy_score(y, y_pred)))\n",
    "    df_teste[label] = y_pred\n",
    "\n",
    "  return df_teste\n",
    "\n",
    "#modelo\n",
    "df_teste = ModelLoad(X_dtm,df_teste,\"wiki\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
